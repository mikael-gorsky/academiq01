Using GPT-5.2
=============

Learn best practices, features, and migration guidance for GPT-5.2 and the GPT-5 model family.

GPT-5.2 is our best general-purpose model, part of the GPT-5 flagship model family. Our most intelligent model yet for both general and agentic tasks, GPT-5.2 shows improvements over the previous GPT-5.1 in:

* General intelligence
* Instruction following
* Accuracy and token efficiency
* Multimodality—especially vision
* Code generation—especially front-end UI creation
* Tool calling and context management in the API
* Spreadsheet understanding and creation

Unlike the previous GPT-5.1 model, GPT-5.2 has new features for managing what the model "knows" and "remembers to improve accuracy.

This guide covers key features of the GPT-5 model family and how to get the most out of GPT-5.2.

IMPORTANT: GPT-5.2 works with BOTH APIs:
1. Responses API: /v1/responses (with "input" field, "reasoning.effort" parameter)
2. Chat Completions API: /v1/chat/completions (with "messages" array, "reasoning_effort" parameter)

For GPT-5.2 with reasoning_effort set to "none", you CAN use:
- temperature
- top_p
- logprobs
- response_format (JSON mode)

CHAT COMPLETIONS API FORMAT:
POST https://api.openai.com/v1/chat/completions
{
  "model": "gpt-5.2",
  "messages": [
    {
      "role": "user",
      "content": "Your prompt here"
    }
  ],
  "reasoning_effort": "none",
  "response_format": { "type": "json_object" }
}

RESPONSES API FORMAT:
POST https://api.openai.com/v1/responses
{
  "model": "gpt-5.2",
  "input": "Your prompt here",
  "reasoning": {
    "effort": "none"
  }
}

Meet the models
---------------

There are three new models. In general, `gpt-5.2` is best for your most complex tasks that require broad world knowledge. It replaces the previous `gpt-5.1` model. The model powering ChatGPT is `gpt-5.2-chat-latest`. Third, `gpt-5.2-pro` uses more compute to think harder and provide consistently better answers.

For a smaller model, use `gpt-5-mini`.

To help you pick the model that best fits your use case, consider these tradeoffs:

| Variant | Best for |
|---|---|
| gpt-5.2 | Complex reasoning, broad world knowledge, and code-heavy or multi-step agentic tasks |
| gpt-5.2-pro | Tough problems that may take longer to solve but require harder thinking |
| gpt-5.1-codex-max | Companies building interactive coding products; full spectrum of coding tasks |
| gpt-5-mini | Cost-optimized reasoning and chat; balances speed, cost, and capability |
| gpt-5-nano | High-throughput tasks, especially simple instruction-following or classification |

New features in GPT-5.2
------------------------

Just like GPT-5.1, the new GPT-5.2 has API features like custom tools, parameters to control verbosity and reasoning, and an allowed tools list. What's new in 5.2 is a new `xhigh` reasoning effort level, concise reasoning summaries, and new context management using _compaction_.

This guide walks through some of the key features of the GPT-5 model family and how to get the most out of 5.2 in particular.

For coding tasks, GPT-5.1-Codex-Max is a faster, more capable, and more token-efficient coding variant, with an `xhigh` reasoning option. Its new built-in compaction capability provides native long-running task support.

Lower reasoning effort
----------------------

The `reasoning.effort` parameter (Responses API) or `reasoning_effort` parameter (Chat Completions API) controls how many reasoning tokens the model generates before producing a response. Earlier reasoning models like o3 supported only `low`, `medium`, and `high`: `low` favored speed and fewer tokens, while `high` favored more thorough reasoning.

With GPT-5.2, the lowest setting is `none` to provide lower-latency interactions. This is the default setting in GPT-5.2. If you need more thinking, slowly increase to `medium` and experiment with results.

With reasoning effort set to `none`, prompting is important. To improve the model's reasoning quality, even with the default settings, encourage it to "think" or outline its steps before answering.

Migration guidance
------------------

GPT-5.2 is our best model yet, and it works best with the Responses API, which supports for passing chain of thought (CoT) between turns. Read below to migrate from your current model or API.

Migrating from other models to GPT-5.2
---------------------------------------

While the model should be close to a drop-in replacement for GPT-5.1, there are a few key changes to call out. See the GPT-5.2 prompting guide for specific updates to make in your prompts.

Using GPT-5 models with the Responses API provides improved intelligence because of the API's design. The Responses API can pass the previous turn's CoT to the model. This leads to fewer generated reasoning tokens, higher cache hit rates, and less latency. To learn more, see an in-depth guide on the benefits of the Responses API.

When migrating to GPT-5.2 from an older OpenAI model, start by experimenting with reasoning levels and prompting strategies. Based on our testing, we recommend using our prompt optimizer—which automatically updates your prompts for GPT-5.2 based on our best practices—and following this model-specific guidance:

* gpt-5.1: `gpt-5.2` with default settings is meant to be a drop-in replacement.
* o3: `gpt-5.2` with `medium` or `high` reasoning. Start with `medium` reasoning with prompt tuning, then increase to `high` if you aren't getting the results you want.
* gpt-4.1: `gpt-5.2` with `none` reasoning. Start with `none` and tune your prompts; increase if you need better performance.
* o4-mini or gpt-4.1-mini: `gpt-5-mini` with prompt tuning is a great replacement.
* gpt-4.1-nano: `gpt-5-nano` with prompt tuning is a great replacement.

GPT-5.2 parameter compatibility
--------------------------------

The following parameters are ONLY supported when using GPT-5.2 with reasoning effort set to `none`:

* temperature
* top_p
* logprobs

Requests to GPT-5.2 or GPT-5.1 with any other reasoning effort setting, or to older GPT-5 models (e.g., `gpt-5`, `gpt-5-mini`, `gpt-5-nano`) that include these fields will raise an error.

To achieve similar results with reasoning effort set higher, or with another GPT-5 family model, try these alternative parameters:

* Reasoning depth: `reasoning: { effort: "none" | "low" | "medium" | "high" | "xhigh" }`
* Output verbosity: `text: { verbosity: "low" | "medium" | "high" }`
* Output length: `max_output_tokens`

Migrating from Chat Completions to Responses API
-------------------------------------------------

The biggest difference, and main reason to migrate from Chat Completions to the Responses API for GPT-5.2, is support for passing chain of thought (CoT) between turns. See a full comparison of the APIs.

Passing CoT exists only in the Responses API, and we've seen improved intelligence, fewer generated reasoning tokens, higher cache hit rates, and lower latency as a result of doing so. Most other parameters remain at parity, though the formatting is different. Here's how new parameters are handled differently between Chat Completions and the Responses API:

Reasoning effort
----------------

Responses API:
curl --request POST \
--url https://api.openai.com/v1/responses \
--header "Authorization: Bearer $OPENAI_API_KEY" \
--header 'Content-type: application/json' \
--data '{
  "model": "gpt-5.2",
  "input": "How much gold would it take to coat the Statue of Liberty in a 1mm layer?",
  "reasoning": {
    "effort": "none"
  }
}'

Chat Completions API:
curl --request POST \
--url https://api.openai.com/v1/chat/completions \
--header "Authorization: Bearer $OPENAI_API_KEY" \
--header 'Content-type: application/json' \
--data '{
  "model": "gpt-5.2",
  "messages": [
    {
      "role": "user",
      "content": "How much gold would it take to coat the Statue of Liberty in a 1mm layer?"
    }
  ],
  "reasoning_effort": "none"
}'

Verbosity
---------

Responses API:
curl --request POST \
--url https://api.openai.com/v1/responses \
--header "Authorization: Bearer $OPENAI_API_KEY" \
--header 'Content-type: application/json' \
--data '{
  "model": "gpt-5.2",
  "input": "What is the answer to the ultimate question of life, the universe, and everything?",
  "text": {
    "verbosity": "low"
  }
}'

Chat Completions API:
curl --request POST \
--url https://api.openai.com/v1/chat/completions \
--header "Authorization: Bearer $OPENAI_API_KEY" \
--header 'Content-type: application/json' \
--data '{
  "model": "gpt-5.2",
  "messages": [
    { "role": "user", "content": "What is the answer to the ultimate question of life, the universe, and everything?" }
  ],
  "verbosity": "low"
}'

KEY POINTS FOR IMPLEMENTATION:
1. Use /v1/chat/completions endpoint (NOT /v1/responses for now)
2. Use "messages" array with role/content structure
3. Set "reasoning_effort": "none" for fastest responses
4. Can use "response_format": { "type": "json_object" } for JSON mode
5. Model names: gpt-5-mini, gpt-5, gpt-5.2, gpt-5.2-pro
